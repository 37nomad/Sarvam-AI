{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10996911,"sourceType":"datasetVersion","datasetId":6845465},{"sourceId":11011760,"sourceType":"datasetVersion","datasetId":6856011},{"sourceId":11012075,"sourceType":"datasetVersion","datasetId":6856205},{"sourceId":11021657,"sourceType":"datasetVersion","datasetId":6863211}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"56f41aa8-544e-437d-ab38-ebce9a5b31a5","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T20:53:06.536544Z","iopub.execute_input":"2025-03-12T20:53:06.536909Z","iopub.status.idle":"2025-03-12T20:53:06.837209Z","shell.execute_reply.started":"2025-03-12T20:53:06.536876Z","shell.execute_reply":"2025-03-12T20:53:06.836570Z"}},"outputs":[],"execution_count":1},{"id":"4586c0f6-4dc7-4c68-89f6-520cbd0fdc2d","cell_type":"code","source":"image_names_finetuning = [d[\"image\"] for d in data]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:16:45.211024Z","iopub.execute_input":"2025-03-13T18:16:45.211323Z","iopub.status.idle":"2025-03-13T18:16:45.236588Z","shell.execute_reply.started":"2025-03-13T18:16:45.211300Z","shell.execute_reply":"2025-03-13T18:16:45.235042Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-91-0cb7db916166>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_names_finetuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"],"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error"},{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n","output_type":"stream"}],"execution_count":91},{"id":"273e5b8c-64ed-4e3d-9512-cb8738ebba1f","cell_type":"code","source":"import random\nimage_names_finetuning = random.sample(image_names_finetuning, 97)\nlen(image_names_finetuning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:16:51.718752Z","iopub.execute_input":"2025-03-13T18:16:51.719063Z","iopub.status.idle":"2025-03-13T18:16:51.741533Z","shell.execute_reply.started":"2025-03-13T18:16:51.719038Z","shell.execute_reply":"2025-03-13T18:16:51.740450Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-ff7084f3329d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_names_finetuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_names_finetuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m97\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_names_finetuning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'image_names_finetuning' is not defined"],"ename":"NameError","evalue":"name 'image_names_finetuning' is not defined","output_type":"error"}],"execution_count":92},{"id":"4311f3f7-a9cc-4ea0-95c1-6cfe4be04c52","cell_type":"code","source":"image_names_test = [d[\"image\"] for d in data if d[\"image\"] not in image_names_finetuning]\nlen(image_names_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:17:07.853622Z","iopub.execute_input":"2025-03-13T18:17:07.853990Z","iopub.status.idle":"2025-03-13T18:17:07.877318Z","shell.execute_reply.started":"2025-03-13T18:17:07.853959Z","shell.execute_reply":"2025-03-13T18:17:07.876262Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-4d662781b801>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_names_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_names_finetuning\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_names_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"],"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error"}],"execution_count":93},{"id":"d3c0336b-4b37-4814-8673-abb3bc434e7a","cell_type":"code","source":"import os\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:20:08.587121Z","iopub.execute_input":"2025-03-13T18:20:08.587471Z","iopub.status.idle":"2025-03-13T18:20:08.590745Z","shell.execute_reply.started":"2025-03-13T18:20:08.587443Z","shell.execute_reply":"2025-03-13T18:20:08.590062Z"}},"outputs":[],"execution_count":94},{"id":"b5ab4b60-d793-41c8-902b-2a7efe964086","cell_type":"code","source":"import os\nimport shutil\n\n# Paths\nsource_folder = \"/kaggle/input/images\"  # Folder where all images are stored\ndest_folder_1 = \"/kaggle/working/finetuning\"  # First new folder\ndest_folder_2 = \"/kaggle/working/test\"  # Second new folder\n\n# Ensure destination folders exist\nos.makedirs(dest_folder_1, exist_ok=True)\nos.makedirs(dest_folder_2, exist_ok=True)\n\n# Lists of selected images\nselected_images_1 = image_names_finetuning  # Modify as needed\nselected_images_2 = image_names_test  # Modify as needed\n\n# Function to copy images\ndef copy_images(image_list, destination):\n    for image_name in image_list:\n        source_path = os.path.join(source_folder, image_name)\n        dest_path = os.path.join(destination, image_name)\n        \n        if os.path.exists(source_path):  # Check if image exists in source\n            shutil.copy(source_path, dest_path)\n        else:\n            print(f\"Warning: {image_name} not found in {source_folder}\")\n\n# Copy images to respective folders\ncopy_images(selected_images_1, dest_folder_1)\ncopy_images(selected_images_2, dest_folder_2)\n\nprint(\"Images copied successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:20:10.199580Z","iopub.execute_input":"2025-03-13T18:20:10.199921Z","iopub.status.idle":"2025-03-13T18:20:10.224447Z","shell.execute_reply.started":"2025-03-13T18:20:10.199858Z","shell.execute_reply":"2025-03-13T18:20:10.223284Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-95-3ab741e27932>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Lists of selected images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mselected_images_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_names_finetuning\u001b[0m  \u001b[0;31m# Modify as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mselected_images_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_names_test\u001b[0m  \u001b[0;31m# Modify as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'image_names_finetuning' is not defined"],"ename":"NameError","evalue":"name 'image_names_finetuning' is not defined","output_type":"error"}],"execution_count":95},{"id":"7a8f6d9d-609c-43c0-bfe4-993e8929bf98","cell_type":"code","source":"import shutil\n\n# Paths of folders to be zipped\nfolder1 = \"/kaggle/working/finetuning\"\nfolder2 = \"/kaggle/working/test\"\n\n# Output zip file paths\nshutil.make_archive(\"folder1_backup\", 'zip', folder1)\nshutil.make_archive(\"folder2_backup\", 'zip', folder2)\n\nprint(\"Folders zipped successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:20:10.724507Z","iopub.execute_input":"2025-03-13T18:20:10.724789Z","iopub.status.idle":"2025-03-13T18:20:10.729782Z","shell.execute_reply.started":"2025-03-13T18:20:10.724767Z","shell.execute_reply":"2025-03-13T18:20:10.729161Z"}},"outputs":[{"name":"stdout","text":"Folders zipped successfully!\n","output_type":"stream"}],"execution_count":96},{"id":"a3e3a189-0dd6-4c37-a74f-c3a1f2bd1899","cell_type":"code","source":"!huggingface-cli login --token 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","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:20:10.948821Z","iopub.execute_input":"2025-03-13T18:20:10.949128Z","iopub.status.idle":"2025-03-13T18:20:12.238606Z","shell.execute_reply.started":"2025-03-13T18:20:10.949106Z","shell.execute_reply":"2025-03-13T18:20:12.237721Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nThe token `Llama-3.2-11B-Vision` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `Llama-3.2-11B-Vision`\n","output_type":"stream"}],"execution_count":97},{"id":"2653e01a-8db3-494f-87c7-23967b45c686","cell_type":"code","source":"import json\n\n# # Sample JSON data (list of dictionaries)\n# data = [\n#     {\"image\": \"image1.jpg\", \"text\": \"Extracted text from image1\"},\n#     {\"image\": \"image2.jpg\", \"text\": \"Extracted text from image2\"},\n#     {\"image\": \"image3.jpg\", \"text\": \"Extracted text from image3\"}\n# ]\n\n# Convert list of dictionaries to a single dictionary\nconverted_data = {d[\"image\"]: d[\"text\"] for d in data}\n\n# Save to a JSON file\njson_filename = \"ground_truth_cleaned.json\"\nwith open(json_filename, \"w\") as json_file:\n    json.dump(converted_data, json_file, indent=4)\n\nprint(f\"JSON file saved as {json_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:20:12.239952Z","iopub.execute_input":"2025-03-13T18:20:12.240259Z","iopub.status.idle":"2025-03-13T18:20:12.284607Z","shell.execute_reply.started":"2025-03-13T18:20:12.240235Z","shell.execute_reply":"2025-03-13T18:20:12.283243Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-98-0c0b43e2e45c>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Convert list of dictionaries to a single dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mconverted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Save to a JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"],"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error"}],"execution_count":98},{"id":"33569b04-3abe-4389-9705-94b943e626fa","cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom transformers import MllamaForConditionalGeneration, AutoProcessor\n\n# Load model and processor\nmodel_id = \"meta-llama/Llama-3.2-11B-Vision\"\nmodel = MllamaForConditionalGeneration.from_pretrained(\n    model_id,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n)\nprocessor = AutoProcessor.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:20:12.285033Z","iopub.status.idle":"2025-03-13T18:20:12.285282Z","shell.execute_reply":"2025-03-13T18:20:12.285178Z"}},"outputs":[],"execution_count":null},{"id":"422b972f-0f86-48a6-9d4e-a4ceee133934","cell_type":"code","source":"with open(\"/kaggle/input/ground-truth-text/ground_truth_cleaned.json\", \"r\") as file:\n    data = json.load(file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:20:12.286057Z","iopub.status.idle":"2025-03-13T18:20:12.286451Z","shell.execute_reply":"2025-03-13T18:20:12.286274Z"}},"outputs":[],"execution_count":null},{"id":"a34649cc-a0eb-4645-a286-c7167eabe37d","cell_type":"code","source":"# Path to your image\nimage_path = \"/kaggle/input/images/india_news_p000142.jpg\"\nimage_name = \"india_news_p000142.jpg\"\nground_truth = data[image_name]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:20:12.287269Z","iopub.status.idle":"2025-03-13T18:20:12.287648Z","shell.execute_reply":"2025-03-13T18:20:12.287481Z"}},"outputs":[],"execution_count":null},{"id":"78cbe250-5bd5-4f82-93cc-bcba34b3c489","cell_type":"code","source":"# Function to perform OCR\ndef extract_text(image_path):\n    image = Image.open(image_path)\n    prompt = \"<|image|><|begin_of_text|>Extract all visible text from this image accurately:\"\n    replaced_prompt = \"Extract all visible text from this image accurately:\"\n    \n    inputs = processor(image, prompt, return_tensors=\"pt\").to(model.device)\n    output = model.generate(**inputs, max_new_tokens=900)  # Adjust max tokens if needed\n    \n    extracted_text = processor.decode(output[0], skip_special_tokens=True)\n    extracted_text = extracted_text.split(replaced_prompt)[-1].strip()\n    return extracted_text\n\n# Perform OCR on a single image\nextracted_text = extract_text(image_path)\n\n# Print extracted text and ground truth\nprint(\"Extracted Text:\", extracted_text)\nprint(\"Ground Truth:\", ground_truth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T23:46:26.427188Z","iopub.execute_input":"2025-03-12T23:46:26.427503Z","iopub.status.idle":"2025-03-12T23:48:35.566267Z","shell.execute_reply.started":"2025-03-12T23:46:26.427480Z","shell.execute_reply":"2025-03-12T23:48:35.565362Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Extracted Text: put in place a machinery for establishment of a mall box system to file patents and according exclusive marketing rights for 5 years. This provision was made in the Patents (Amendment) Act of 1999. Copyright protection in India India has one of the most modern copyright protection laws in the world. Major development in the area of copyright during 1999 was the amendment to the Copyright Act of 1957 to make it fully compatible with the provisions of the TRIPS Agreement. Called the Copyright (Amendment) Act, 1999, this amendment was signed by the President of India on December 30, 1999 and came into force on January 15, 2000. The earlier 1994 amendment to the Copyright Act of 1957 had provided protection to all original literary, dramatic, musical and artistic works, cinematography, films and sound recordings. It also brought sectors such as satellite broadcasting, computer software and digital technology under Indian copyright protection. The Copyright Act is now in full conformity with the TRIPS obligations. Concern has been expressed about the allegedly slow judicial system in India and the procedural issues involved in trial and conviction. The Indian judiciary is handling cases as expeditiously as possible. The year that has gone by has again witnessed the versatility of the impartial and independent interpretation of intellectual property rights, amplified by the tion of intellectual property rights, amplified by the gaps in the statute with the common sense of the common law. Indian enforcement agencies are working effectively and there is a decline in the levels of piracy in India. A summary of these measures is given below: 1. During the year the government continued to stress the need for strict enforcement of the Copyright Act and Rules. State governments and other Ministries were regularly requested to lay special attention to ensuring copyright protection in their functioning. The Government also brought out a Handbook of Copyright Law to create awareness about copyright right amongst the stakeholders, enforcement agencies, professional users like the scientific and academic communities and members of the public. Copies of the Handbook were circulated free of cost to the state and central government officials and police personnel and also provided to participants in various seminars and workshops on IPR matters held during the year. National Police Academy and National Academy of Customs, Excise and Narcotics conducted several training programs on copyright for the police and customs officers. Modules on copyright have been included in their regular training programs. The Department of Education, Ministry of Human Resource Development, Government of India has initiated several measures in the past for strengthening the enforcement of copyrights that include constitution of a Copyright Enforcement Advisory Council (CEAC), creation of separate cells in state police headquarters, encouraging setting up of collective administration societies and organization of seminars and workshops to create greater awareness about copyright law among the enforcement personnel and the general public. For collective administration of copyright, copyright societies have been set up for different classes of works. At present there are three registered copyright societies. These are the Society for Copyright Regulations (SCRIPT) for cinematography films, Indian Performing Rights Society Limited (IPRS) for musical works and Phonographic Performance Limited (PPL) for sound recordings. These societies, particularly the PPL and the IPRS, have been quite active in anti-piracy work. The PPL has even set up a special anti-piracy cell under a retired Director General of Police, and this cell has been working in tandem with the police. Several other measures to create general awareness about copyright and for encouraging study of intellectual property rights in the educational system, besides modernizing the Copyright Of- fice, are on the anvil. Consequent to the number of measures initiated by the government, there has been more activity in the enforcement of copyright laws in the country during the last year compared to previous years. As per the data relating to copyright offenses available with the National Crime Records Bureau, the number of copy- right cases registered has gone up from 479 in 1997 to 802 in 1998. The number of persons arrested has increased from 794 in 1997 to 980 in 1998. The value of seizures has gone up from Rs. 28.8 million in 1997 to Rs. 74.8 million in 1998. These figures reflect the general improvement in the enforcement of the copyright law. Digitized by Google Original from UNIVERSITY OF VIRGINIA. <OCR/> mall place machinery establishment system patents according rights years. the Patents (Amendment) Act made police pants various\nGround Truth: put in place a machinery for establishment of a\nmail box system to file patents and according\nexclusive marketing rights for 5 years. This pro-\nvision was made in the Patents (Amendment) Act\nof 1999.\n\nCopyright protection in India\n\nIndia has one of the most modern copyright protec-\ntion laws in the world. Major development in the\narea of copyright during 1999 was the amendment\nto the Copyright Act of 1957 to make it fully compat-\nible with the provisions of the TRIPS Agreement.\nCalled the Copyright (Amendment) Act, 1999, this\namendment was signed by the President of India on\nDecember 30, 1999 and came into force on January\n15, 2000.\n\nThe earlier 1994 amendment to the Copyright Act of\n1957 had provided protection to all original literary,\ndramatic, musical and artistic works, cinematogra-\nphy, films and sound recordings. It also brought\nsectors such as satellite broadcasting, computer soft-\nware and digital technology under Indian copyright\nprotection. The Copyright Act is now in full confor-\nmity with the TRIPS obligations.\n\nConcern has been expressed about the allegedly\nslow judicial system in India and the procedural\nissues involved in trial and conviction. The Indian\njudiciary is handling cases as expeditiously as pos-\nsible. The year that has gone by has again witnessed\nthe versatility of the impartial and independent In-\ndian judiciary when it comes to the issue of protec-\ntion of intellectual property rights, amplified by the\nencouraging trends with Indian courts plugging in\ngaps in the statute with the common sense of the\ncommon law.\n\nIndian enforcement agencies are working effectively\nand there is a decline in the levels of piracy in India.\nA summary of these measures is given below:\n\n1. During the year the government continued to stress\nthe need for strict enforcement of the Copyright\nAct and Rules. State governments and other Min-\nistries were regularly requested to lay special at-\ntention to ensuring copyright protection in their\nfunctioning.\n\n2. The Government also brought out a Handbook of\nCopyright Law to create awareness about copy-\nright amongst the stakeholders, enforcement agen-\ncies, professional users like the scientific and aca-\ndemic communities and members of the public.\nCopies of the Handbook were circulated free of\ncost to the state and central government officials\n\nand police personnel and also provided to partici-\npants in various seminars and workshops on IPR\nmatters held during the year.\n\n3. National Police Academy and National Academy\nof Customs, Excise and Narcotics conducted sev-\neral training programs on copyright for the police\nand customs officers. Modules on copyright have\nbeen included in their regular training programs.\n\n4. The Department of Education, Ministry of Human\nResource Development, Government of India has\ninitiated several measures in the past for strength-\nening the enforcement of copyrights that include\nconstitution of a Copyright Enforcement Advisory\nCouncil (CEAC), creation of separate cells in state\npolice headquarters, encouraging setting up of\ncollective administration societies and organiza-\ntion of seminars and workshops to create greater\nawareness about copyright law among the en-\nforcement personnel and the general public.\n\n5. For collective administration of copyright, copy-\nright societies have been set up for different classes\nof works. At present there are three registered\ncopyright societies. These are the Society for\nCopyright Regulations of Indian Producers of Films\n& Television (SCRIPT) for cinematography films,\nIndian Performing Rights Society Limited (IPRS)\nfor musical works and Phonographic Performance\nLimited (PPL) for sound recordings. These societ-\nies, particularly the PPL and the IPRS, have been\nquite active in anti-piracy work. The PPL has even\nset up a special anti-piracy cell under a retired\nDirector General of Police, and this cell has been\nworking in tandem with the police.\n\n6. Several other measures to create general aware-\nness about copyright and for encouraging study\nof intellectual property rights in the educational\nsystem, besides modernizing the Copyright Of-\nfice, are on the anvil.\n\nConsequent to the number of measures initiated by\nthe government, there has been more activity in the\nenforcement of copyright laws in the country during\nthe last year compared to previous years. As per the\ndata relating to copyright offenses available with the\nNational Crime Records Bureau, the number of copy-\nright cases registered has gone up from 479 in 1997\nto 802 in 1998. The number of persons arrested has\nincreased from 794 in 1997 to 980 in 1998. The\nvalue of seizures has gone up from Rs. 28.8 million\nin 1997 to Rs.74.8 million in 1998. These figures\nreflect the general improvement in the enforcement\nof the copyright law.\n\n \n\nGoogle\n\n \n\n17\n\f\n","output_type":"stream"}],"execution_count":67},{"id":"059d5fb3-e942-4b3f-b6e9-4179b9c2c82b","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c84f542a-ab72-460b-8926-c3f5f37308af","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"be9ae38b-2514-4bfd-8c63-eaf8e947bb52","cell_type":"code","source":"# pip install jiwer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:21:44.565262Z","iopub.execute_input":"2025-03-13T18:21:44.565643Z","iopub.status.idle":"2025-03-13T18:21:44.569010Z","shell.execute_reply.started":"2025-03-13T18:21:44.565612Z","shell.execute_reply":"2025-03-13T18:21:44.568395Z"}},"outputs":[],"execution_count":1},{"id":"80ab7727-0a51-4f0c-afd0-2777c5c8f1f5","cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\ntorch.cuda.reset_peak_memory_stats()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:21:45.118904Z","iopub.execute_input":"2025-03-13T18:21:45.119115Z","iopub.status.idle":"2025-03-13T18:21:49.959274Z","shell.execute_reply.started":"2025-03-13T18:21:45.119096Z","shell.execute_reply":"2025-03-13T18:21:49.958347Z"}},"outputs":[],"execution_count":2},{"id":"833401e0-f4cb-47b0-9891-8e8a82ef4c29","cell_type":"code","source":"# Paths\ntest_images_folder = \"/kaggle/input/test-dataset\"  # Folder containing test images\nground_truth_json = \"/kaggle/input/ground-truth-text/ground_truth_cleaned.json\"  # JSON file with image-text mapping\n\n# Load ground truth data\nwith open(ground_truth_json, \"r\") as f:\n    ground_truth_data = json.load(f)  # Expecting format: [{\"image\": \"image_name.jpg\", \"text\": \"ground truth text\"}, ...]\n\n# Convert ground truth data to a dictionary for easy lookup\n# ground_truth_dict = {item[\"image\"]: item[\"text\"] for item in ground_truth_data}\nground_truth_dict = ground_truth_data\n\n# Function to extract text from image\ndef extract_text(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    prompt = \"<|image|><|begin_of_text|>Extract all visible text from this image accurately:\"\n    replaced_prompt = \"Extract all visible text from this image accurately:\"\n    \n    inputs = processor(image, prompt, return_tensors=\"pt\").to(model.device)\n    output = model.generate(**inputs, max_new_tokens=900)\n    \n    extracted_text = processor.decode(output[0], skip_special_tokens=True)\n    extracted_text = extracted_text.split(replaced_prompt)[-1].strip()\n    return extracted_text\n\n# Evaluate WER & CER\nwer_scores, cer_scores = [], []\nimage_files = os.listdir(test_images_folder)  # Select only the first 2 images\n\n# Initialize progress bar\nprogress_bar = tqdm(total=len(image_files), desc=\"Processing Images\", unit=\"image\")\n\nfor image_name in tqdm(image_files):\n    image_path = os.path.join(test_images_folder, image_name)\n\n    # Retrieve ground truth text\n    ground_truth_text = ground_truth_dict.get(image_name, \"\")\n\n    # If ground truth is missing, skip this image\n    if not ground_truth_text:\n        print(f\"Skipping {image_name}: No ground truth found.\")\n        continue\n\n    # Extract text using the model\n    predicted_text = extract_text(image_path)\n\n    # Compute WER & CER\n    wer_scores.append(wer(ground_truth_text, predicted_text))\n    cer_scores.append(cer(ground_truth_text, predicted_text))\n\n    progress_bar.update(1)\n\nprogress_bar.close()\n\n# Compute final scores\naverage_wer = sum(wer_scores) / len(wer_scores)\naverage_cer = sum(cer_scores) / len(cer_scores)\n\nprint(f\"Average WER: {average_wer:.4f}\")\nprint(f\"Average CER: {average_cer:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T11:18:11.421015Z","iopub.execute_input":"2025-03-13T11:18:11.421382Z","iopub.status.idle":"2025-03-13T12:27:11.901696Z","shell.execute_reply.started":"2025-03-13T11:18:11.421352Z","shell.execute_reply":"2025-03-13T12:27:11.901010Z"}},"outputs":[{"name":"stderr","text":"\nProcessing Images:   0%|          | 0/2 [08:33<?, ?image/s]]\u001b[A\n  0%|          | 0/40 [00:00<?, ?it/s]\n  2%|▎         | 1/40 [01:44<1:07:50, 104.37s/it]:07:50, 104.37s/image]\u001b[A\n  5%|▌         | 2/40 [03:27<1:05:48, 103.91s/it]:05:48, 103.91s/image]\u001b[A\n  8%|▊         | 3/40 [05:11<1:03:57, 103.71s/it]:03:57, 103.71s/image]\u001b[A\n 10%|█         | 4/40 [06:54<1:02:11, 103.64s/it]:02:11, 103.64s/image]\u001b[A\n 12%|█▎        | 5/40 [08:38<1:00:26, 103.63s/it]:00:26, 103.63s/image]\u001b[A\n 15%|█▌        | 6/40 [10:22<58:42, 103.59s/it]  8:42, 103.59s/image]  \u001b[A\n 18%|█▊        | 7/40 [12:05<56:57, 103.57s/it]<56:57, 103.57s/image]\u001b[A\n 20%|██        | 8/40 [13:49<55:14, 103.56s/it]<55:14, 103.56s/image]\u001b[A\n 22%|██▎       | 9/40 [15:32<53:29, 103.52s/it]<53:29, 103.52s/image]\u001b[A\n 25%|██▌       | 10/40 [17:15<51:44, 103.47s/it]<51:44, 103.47s/image]\u001b[A\n 28%|██▊       | 11/40 [18:59<50:00, 103.45s/it]<50:00, 103.45s/image]\u001b[A\n 30%|███       | 12/40 [20:42<48:17, 103.47s/it]<48:17, 103.47s/image]\u001b[A\n 32%|███▎      | 13/40 [22:26<46:33, 103.45s/it]<46:33, 103.45s/image]\u001b[A\n 35%|███▌      | 14/40 [24:09<44:48, 103.42s/it]<44:48, 103.42s/image]\u001b[A\n 38%|███▊      | 15/40 [25:53<43:05, 103.43s/it]<43:05, 103.43s/image]\u001b[A\n 40%|████      | 16/40 [27:36<41:24, 103.50s/it]<41:24, 103.50s/image]\u001b[A\n 42%|████▎     | 17/40 [29:20<39:41, 103.55s/it]<39:41, 103.55s/image]\u001b[A\n 45%|████▌     | 18/40 [31:03<37:58, 103.55s/it]<37:58, 103.55s/image]\u001b[A\n 48%|████▊     | 19/40 [32:47<36:15, 103.58s/it]<36:15, 103.58s/image]\u001b[A\n 50%|█████     | 20/40 [34:31<34:31, 103.55s/it]<34:31, 103.55s/image]\u001b[A\n 52%|█████▎    | 21/40 [36:14<32:47, 103.54s/it]<32:47, 103.54s/image]\u001b[A\n 55%|█████▌    | 22/40 [37:58<31:03, 103.53s/it]<31:03, 103.53s/image]\u001b[A\n 60%|██████    | 24/40 [41:25<27:36, 103.55s/it]<27:36, 103.55s/image]\u001b[A\n 62%|██████▎   | 25/40 [43:08<25:53, 103.53s/it]<25:53, 103.53s/image]\u001b[A\n 65%|██████▌   | 26/40 [44:52<24:09, 103.55s/it]<24:09, 103.55s/image]\u001b[A\n 68%|██████▊   | 27/40 [46:35<22:25, 103.52s/it]<22:25, 103.52s/image]\u001b[A\n 70%|███████   | 28/40 [48:19<20:41, 103.49s/it]<20:41, 103.49s/image]\u001b[A\n 72%|███████▎  | 29/40 [50:02<18:58, 103.50s/it]<18:58, 103.50s/image]\u001b[A\n 75%|███████▌  | 30/40 [51:46<17:15, 103.51s/it]<17:15, 103.51s/image]\u001b[A\n 78%|███████▊  | 31/40 [53:29<15:31, 103.52s/it]<15:31, 103.52s/image]\u001b[A\n 80%|████████  | 32/40 [55:13<13:48, 103.51s/it]<13:48, 103.51s/image]\u001b[A\n 82%|████████▎ | 33/40 [56:56<12:04, 103.46s/it]<12:04, 103.46s/image]\u001b[A\n 85%|████████▌ | 34/40 [58:40<10:20, 103.45s/it]<10:20, 103.45s/image]\u001b[A\n 88%|████████▊ | 35/40 [1:00:23<08:37, 103.45s/it]<08:37, 103.45s/image]\u001b[A\n 90%|█████████ | 36/40 [1:02:06<06:53, 103.43s/it]<06:53, 103.43s/image]\u001b[A\n 92%|█████████▎| 37/40 [1:03:50<05:10, 103.42s/it]<05:10, 103.42s/image]\u001b[A\n 95%|█████████▌| 38/40 [1:05:33<03:26, 103.41s/it]<03:26, 103.41s/image]\u001b[A\n 98%|█████████▊| 39/40 [1:07:17<01:43, 103.41s/it]<01:43, 103.41s/image]\u001b[A\n100%|██████████| 40/40 [1:09:00<00:00, 103.51s/it]<00:00, 103.39s/image]\u001b[A\nProcessing Images: 100%|██████████| 40/40 [1:09:00<00:00, 103.51s/image]","output_type":"stream"},{"name":"stdout","text":"Average WER: 2.2440\nAverage CER: 2.0135\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"id":"e9a5c28c-01f2-4175-85f2-f37095824719","cell_type":"code","source":"wer_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T12:31:33.045047Z","iopub.execute_input":"2025-03-13T12:31:33.045384Z","iopub.status.idle":"2025-03-13T12:31:33.050685Z","shell.execute_reply.started":"2025-03-13T12:31:33.045355Z","shell.execute_reply":"2025-03-13T12:31:33.049893Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[0.7518072289156627,\n 0.7033707865168539,\n 0.39361702127659576,\n 0.4772727272727273,\n 0.45077720207253885,\n 0.3729903536977492,\n 0.853904282115869,\n 0.8076285240464345,\n 0.5024154589371981,\n 2.65,\n 0.9528985507246377,\n 0.6453900709219859,\n 0.5962059620596206,\n 0.7193675889328063,\n 0.8324607329842932,\n 0.9277456647398844,\n 0.5731958762886598,\n 0.5721830985915493,\n 0.5871559633027523,\n 2.0727969348659006,\n 0.46153846153846156,\n 0.2253922967189729,\n 0.5863267670915412,\n 0.6684397163120568,\n 1.583710407239819,\n 0.6673114119922631,\n 0.31490015360983103,\n 0.3746928746928747,\n 0.43451776649746193,\n 0.44411326378539495,\n 0.4294385432473445,\n 0.9401041666666666,\n 0.34449093444909346,\n 0.35419440745672437,\n 0.7054409005628518,\n 0.5396419437340153,\n 0.9267326732673268,\n 0.6095791001451378,\n 62.22222222222222,\n 0.4846743295019157]"},"metadata":{}}],"execution_count":11},{"id":"53da2c25-71f3-482a-a451-94f92efc0e83","cell_type":"code","source":"cer_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T12:31:48.889972Z","iopub.execute_input":"2025-03-13T12:31:48.890253Z","iopub.status.idle":"2025-03-13T12:31:48.895542Z","shell.execute_reply.started":"2025-03-13T12:31:48.890231Z","shell.execute_reply":"2025-03-13T12:31:48.894725Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[0.5530329904221355,\n 0.4834289356277884,\n 0.2672086720867209,\n 0.36010620643876534,\n 0.08818635607321132,\n 0.1719446399249355,\n 0.7372145384367964,\n 0.6281227694503926,\n 0.2770448548812665,\n 2.551699716713881,\n 0.899641577060932,\n 0.5277777777777778,\n 0.4519309778142975,\n 0.4860568878973787,\n 0.7503579952267303,\n 0.8404255319148937,\n 0.3322188449848024,\n 0.42442008666836606,\n 0.278264497288277,\n 1.7348916761687572,\n 0.12179930795847752,\n 0.036885245901639344,\n 0.4247472856608012,\n 0.45392749244712993,\n 1.1933911159263273,\n 0.4442328618063112,\n 0.12578488960907433,\n 0.18241563055062168,\n 0.2983561222922108,\n 0.10186153524367288,\n 0.08379888268156424,\n 0.8081639803784163,\n 0.13385986229242608,\n 0.1568663257852447,\n 0.5457446808510639,\n 0.4575692963752665,\n 0.7584783249778826,\n 0.32176105508145847,\n 60.64102564102564,\n 0.40563056592933067]"},"metadata":{}}],"execution_count":12},{"id":"8bd613b3-1033-4e86-9608-e08fbd79bcda","cell_type":"markdown","source":"# Finetuning Phas","metadata":{}},{"id":"bc1ff083-122a-4c70-a1df-9bcd9f77b444","cell_type":"code","source":"# !pip install -q peft bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T16:34:16.734945Z","iopub.execute_input":"2025-03-13T16:34:16.735327Z","iopub.status.idle":"2025-03-13T16:34:24.053347Z","shell.execute_reply.started":"2025-03-13T16:34:16.735293Z","shell.execute_reply":"2025-03-13T16:34:24.052425Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"id":"9462e098-617f-42ee-9609-051c68524ef4","cell_type":"code","source":"import torch\nfrom transformers import AutoProcessor, MllamaForConditionalGeneration\nfrom peft import LoraConfig, get_peft_model\nfrom PIL import Image\nimport json\nimport os\n\nmodel_id = \"meta-llama/Llama-3.2-11B-Vision\"\nmodel = MllamaForConditionalGeneration.from_pretrained(\n    model_id,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\nprocessor = AutoProcessor.from_pretrained(model_id)\n\nlora_config = LoraConfig(\n    r=8,  # Low-rank adaptation\n    lora_alpha=16,\n    lora_dropout=0.05,\n    bias=\"none\",\n    target_modules=[\"q_proj\", \"v_proj\"]  # LoRA applied to attention layers\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T17:37:15.006941Z","iopub.execute_input":"2025-03-13T17:37:15.007292Z","iopub.status.idle":"2025-03-13T17:38:45.354028Z","shell.execute_reply.started":"2025-03-13T17:37:15.007266Z","shell.execute_reply":"2025-03-13T17:38:45.353067Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20216c1031114d51a19c408725aa69b4"}},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"PeftModel(\n  (base_model): LoraModel(\n    (model): MllamaForConditionalGeneration(\n      (vision_model): MllamaVisionModel(\n        (patch_embedding): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14), padding=valid, bias=False)\n        (gated_positional_embedding): MllamaPrecomputedPositionEmbedding(\n          (tile_embedding): Embedding(9, 5248000)\n        )\n        (pre_tile_positional_embedding): MllamaPrecomputedAspectRatioEmbedding(\n          (embedding): Embedding(9, 5120)\n        )\n        (post_tile_positional_embedding): MllamaPrecomputedAspectRatioEmbedding(\n          (embedding): Embedding(9, 5120)\n        )\n        (layernorm_pre): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (layernorm_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (transformer): MllamaVisionEncoder(\n          (layers): ModuleList(\n            (0-31): 32 x MllamaVisionEncoderLayer(\n              (self_attn): MllamaVisionSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=1280, out_features=1280, bias=False)\n              )\n              (mlp): MllamaVisionMLP(\n                (activation_fn): GELUActivation()\n                (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n                (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n              )\n              (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (global_transformer): MllamaVisionEncoder(\n          (layers): ModuleList(\n            (0-7): 8 x MllamaVisionEncoderLayer(\n              (self_attn): MllamaVisionSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=1280, out_features=1280, bias=False)\n              )\n              (mlp): MllamaVisionMLP(\n                (activation_fn): GELUActivation()\n                (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n                (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n              )\n              (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n      )\n      (language_model): MllamaForCausalLM(\n        (model): MllamaTextModel(\n          (embed_tokens): Embedding(128264, 4096, padding_idx=128004)\n          (layers): ModuleList(\n            (0-2): 3 x MllamaSelfAttentionDecoderLayer(\n              (self_attn): MllamaTextSelfSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              )\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (3): MllamaCrossAttentionDecoderLayer(\n              (cross_attn): MllamaTextCrossSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (4-7): 4 x MllamaSelfAttentionDecoderLayer(\n              (self_attn): MllamaTextSelfSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              )\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (8): MllamaCrossAttentionDecoderLayer(\n              (cross_attn): MllamaTextCrossSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (9-12): 4 x MllamaSelfAttentionDecoderLayer(\n              (self_attn): MllamaTextSelfSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              )\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (13): MllamaCrossAttentionDecoderLayer(\n              (cross_attn): MllamaTextCrossSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (14-17): 4 x MllamaSelfAttentionDecoderLayer(\n              (self_attn): MllamaTextSelfSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              )\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (18): MllamaCrossAttentionDecoderLayer(\n              (cross_attn): MllamaTextCrossSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (19-22): 4 x MllamaSelfAttentionDecoderLayer(\n              (self_attn): MllamaTextSelfSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              )\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (23): MllamaCrossAttentionDecoderLayer(\n              (cross_attn): MllamaTextCrossSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (24-27): 4 x MllamaSelfAttentionDecoderLayer(\n              (self_attn): MllamaTextSelfSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              )\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (28): MllamaCrossAttentionDecoderLayer(\n              (cross_attn): MllamaTextCrossSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (29-32): 4 x MllamaSelfAttentionDecoderLayer(\n              (self_attn): MllamaTextSelfSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              )\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (33): MllamaCrossAttentionDecoderLayer(\n              (cross_attn): MllamaTextCrossSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (34-37): 4 x MllamaSelfAttentionDecoderLayer(\n              (self_attn): MllamaTextSelfSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              )\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (38): MllamaCrossAttentionDecoderLayer(\n              (cross_attn): MllamaTextCrossSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n                (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n                (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n            (39): MllamaSelfAttentionDecoderLayer(\n              (self_attn): MllamaTextSelfSdpaAttention(\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=4096, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=4096, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              )\n              (mlp): MllamaTextMLP(\n                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n              (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n            )\n          )\n          (norm): MllamaTextRMSNorm((4096,), eps=1e-05)\n          (rotary_emb): MllamaRotaryEmbedding()\n        )\n        (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n      )\n      (multi_modal_projector): Linear(in_features=7680, out_features=4096, bias=True)\n    )\n  )\n)"},"metadata":{}}],"execution_count":31},{"id":"afa7468c-5bb6-4b86-90f0-90e394bf4fa0","cell_type":"code","source":"# Paths\nimport json\ndataset_folder = \"/kaggle/input/finetuning-dataset\"\nground_truth_json = \"/kaggle/input/ground-truth-text/ground_truth_cleaned.json\"\n\n# Load ground truth text\nwith open(ground_truth_json, \"r\") as f:\n    ground_truth_data = json.load(f) # [{\"image\": \"img1.jpg\", \"text\": \"actual text\"}, ...]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:22.826804Z","iopub.execute_input":"2025-03-13T18:14:22.827157Z","iopub.status.idle":"2025-03-13T18:14:22.836703Z","shell.execute_reply.started":"2025-03-13T18:14:22.827131Z","shell.execute_reply":"2025-03-13T18:14:22.835733Z"}},"outputs":[],"execution_count":78},{"id":"f17db36e-7187-4137-9d4d-c5a8ca71d47e","cell_type":"code","source":"# Convert JSON to dictionary\nground_truth_dict = ground_truth_data\n\n# Dataset preparation\ntrain_data = []\n# for image_name, text in ground_truth_dict.items():\nfor image_name in os.listdir(dataset_folder):\n    image_path = os.path.join(dataset_folder, image_name)\n    train_data.append({\"image_path\": image_path, \"text\": ground_truth_data[image_name]})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:23.279468Z","iopub.execute_input":"2025-03-13T18:14:23.279740Z","iopub.status.idle":"2025-03-13T18:14:23.284536Z","shell.execute_reply.started":"2025-03-13T18:14:23.279718Z","shell.execute_reply":"2025-03-13T18:14:23.283679Z"}},"outputs":[],"execution_count":79},{"id":"dcd09d35-a47c-47f8-91ba-b2eaa45d83df","cell_type":"code","source":"len(train_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:25.025225Z","iopub.execute_input":"2025-03-13T18:14:25.025508Z","iopub.status.idle":"2025-03-13T18:14:25.030346Z","shell.execute_reply.started":"2025-03-13T18:14:25.025486Z","shell.execute_reply":"2025-03-13T18:14:25.029594Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"97"},"metadata":{}}],"execution_count":80},{"id":"bccf7ef6-b728-4bdd-b869-297f750a8e4e","cell_type":"code","source":"print(processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:25.869654Z","iopub.execute_input":"2025-03-13T18:14:25.869971Z","iopub.status.idle":"2025-03-13T18:14:26.671854Z","shell.execute_reply.started":"2025-03-13T18:14:25.869943Z","shell.execute_reply":"2025-03-13T18:14:26.670734Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"MllamaProcessor:\n- image_processor: MllamaImageProcessor {\n  \"do_convert_rgb\": true,\n  \"do_normalize\": true,\n  \"do_pad\": true,\n  \"do_rescale\": true,\n  \"do_resize\": true,\n  \"image_mean\": [\n    0.48145466,\n    0.4578275,\n    0.40821073\n  ],\n  \"image_processor_type\": \"MllamaImageProcessor\",\n  \"image_std\": [\n    0.26862954,\n    0.26130258,\n    0.27577711\n  ],\n  \"max_image_tiles\": 4,\n  \"resample\": 2,\n  \"rescale_factor\": 0.00392156862745098,\n  \"size\": {\n    \"height\": 448,\n    \"width\": 448\n  }\n}\n\n- tokenizer: PreTrainedTokenizerFast(name_or_path='meta-llama/Llama-3.2-11B-Vision', vocab_size=128000, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>', 'pad_token': '<|finetune_right_pad_id|>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128004: AddedToken(\"<|finetune_right_pad_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128005: AddedToken(\"<|step_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128008: AddedToken(\"<|eom_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128010: AddedToken(\"<|python_tag|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128011: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128012: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128013: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128014: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128015: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128016: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128017: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128018: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128019: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128020: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128021: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128022: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128023: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128024: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128025: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128026: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128027: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128028: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128029: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128030: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128031: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128032: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128033: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128034: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128035: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128036: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128037: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128038: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128039: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128040: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128041: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128042: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128043: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128044: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128045: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128046: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128047: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128048: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128049: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128050: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128051: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128052: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128053: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128054: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128055: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128056: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128057: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128058: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128059: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128060: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128061: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128062: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128063: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128064: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128065: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128066: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128067: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128068: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128069: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128070: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128071: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128072: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128073: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128074: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128075: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128076: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128077: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128078: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128079: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128080: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128081: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128082: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128083: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128084: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128085: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128086: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128087: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128088: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128089: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128090: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128091: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128092: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128093: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128094: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128095: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128096: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128097: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128098: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128099: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128100: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128101: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128102: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128103: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128104: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128105: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128106: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128107: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128108: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128109: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128110: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128111: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128112: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128113: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128114: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128115: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128116: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128117: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128118: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128119: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128120: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128121: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128122: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128123: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128124: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128125: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128126: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128127: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128128: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128129: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128130: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128131: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128132: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128133: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128134: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128135: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128136: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128137: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128138: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128139: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128140: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128141: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128142: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128143: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128144: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128145: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128146: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128147: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128148: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128149: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128150: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128151: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128152: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128153: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128154: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128155: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128156: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128157: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128158: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128159: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128160: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128161: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128162: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128163: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128164: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128165: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128166: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128167: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128168: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128169: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128170: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128171: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128172: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128173: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128174: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128175: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128176: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128177: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128178: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128179: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128180: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128181: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128182: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128183: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128184: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128185: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128186: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128187: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128188: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128189: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128190: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128191: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128192: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128193: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128194: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128195: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128196: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128197: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128198: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128199: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128200: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128201: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128202: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128203: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128204: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128205: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128206: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128207: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128208: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128209: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128210: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128211: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128212: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128213: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128214: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128215: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128216: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128217: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128218: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128219: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128220: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128221: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128222: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128223: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128224: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128225: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128226: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128227: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128228: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128229: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128230: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128231: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128232: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128233: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128234: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128235: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128236: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128237: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128238: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128239: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128240: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128241: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128242: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128243: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128244: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128245: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128246: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128247: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128248: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128249: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128250: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128251: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128252: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128253: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128254: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128255: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t128256: AddedToken(\"<|image|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n}\n)\n\n{\n  \"processor_class\": \"MllamaProcessor\"\n}\n\n","output_type":"stream"}],"execution_count":81},{"id":"5b101a24-9a2b-4ab3-95c9-b77ce103cd4a","cell_type":"code","source":"print(processor.tokenizer.special_tokens_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:30.142514Z","iopub.execute_input":"2025-03-13T18:14:30.142804Z","iopub.status.idle":"2025-03-13T18:14:30.146773Z","shell.execute_reply.started":"2025-03-13T18:14:30.142778Z","shell.execute_reply":"2025-03-13T18:14:30.145970Z"}},"outputs":[{"name":"stdout","text":"{'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>', 'pad_token': '<|finetune_right_pad_id|>'}\n","output_type":"stream"}],"execution_count":82},{"id":"d6465261-34ed-49e0-b6f5-34b34d7ba0b4","cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom transformers import TrainingArguments, Trainer\n\n# Custom Dataset\nclass OCRDataset(Dataset):\n    def __init__(self, data, processor):\n        self.data = data\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.data)\n        \n    # def __getitem__(self, idx):\n        # item = self.data[idx]\n        # image = Image.open(item[\"image_path\"]).convert(\"RGB\")\n        # text = item[\"text\"]\n    \n        # inputs = self.processor(images=image, text=text, return_tensors=\"pt\")\n    \n        # print(f\"Processed Output Keys: {inputs.keys()}\")  # Debugging step\n        # print(f\"Image shape (pixel_values): {inputs.get('pixel_values', None)}\")  # Check if image tokens exist\n\n        # return {k: v.squeeze(0) for k, v in inputs.items()}  # Remove batch dimension\n\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        image = item[\"image\"]\n        text = f\"<image> {item['text']}\"  # Ensure image token is there\n        \n        # ✅ Ensure padding & truncation are enabled\n        inputs = self.processor(images=image, text=text, return_tensors=\"pt\", padding=True, truncation=True)\n    \n        return inputs\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:34.077255Z","iopub.execute_input":"2025-03-13T18:14:34.077540Z","iopub.status.idle":"2025-03-13T18:14:34.083022Z","shell.execute_reply.started":"2025-03-13T18:14:34.077519Z","shell.execute_reply":"2025-03-13T18:14:34.082155Z"}},"outputs":[],"execution_count":83},{"id":"2e2a7b80-2089-42d6-b843-abb8c597d600","cell_type":"code","source":"processor.tokenizer.add_tokens([\"<|image|>\"])\nprint(processor.tokenizer.all_special_tokens)  # Verify it was added","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:35.183777Z","iopub.execute_input":"2025-03-13T18:14:35.184109Z","iopub.status.idle":"2025-03-13T18:14:35.189050Z","shell.execute_reply.started":"2025-03-13T18:14:35.184067Z","shell.execute_reply":"2025-03-13T18:14:35.188296Z"}},"outputs":[{"name":"stdout","text":"['<|begin_of_text|>', '<|end_of_text|>', '<|finetune_right_pad_id|>']\n","output_type":"stream"}],"execution_count":84},{"id":"8d11b769-0b69-455a-bdbb-6e666ef5e70f","cell_type":"code","source":"model.resize_token_embeddings(len(processor.tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:36.156724Z","iopub.execute_input":"2025-03-13T18:14:36.157154Z","iopub.status.idle":"2025-03-13T18:14:36.198765Z","shell.execute_reply.started":"2025-03-13T18:14:36.157120Z","shell.execute_reply":"2025-03-13T18:14:36.197908Z"}},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"Embedding(128257, 4096, padding_idx=128004)"},"metadata":{}}],"execution_count":85},{"id":"26a3f324-e837-4f9b-8970-1028be81622a","cell_type":"code","source":"print(model.forward.__doc__)  # Check expected inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:38.247762Z","iopub.execute_input":"2025-03-13T18:14:38.248090Z","iopub.status.idle":"2025-03-13T18:14:38.252610Z","shell.execute_reply.started":"2025-03-13T18:14:38.248066Z","shell.execute_reply":"2025-03-13T18:14:38.251780Z"}},"outputs":[{"name":"stdout","text":"None\n","output_type":"stream"}],"execution_count":86},{"id":"bcd7332d-ad2f-4e94-a2a2-56d5be2a3244","cell_type":"code","source":"print(processor.tokenizer.all_special_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:39.429898Z","iopub.execute_input":"2025-03-13T18:14:39.430181Z","iopub.status.idle":"2025-03-13T18:14:39.434775Z","shell.execute_reply.started":"2025-03-13T18:14:39.430159Z","shell.execute_reply":"2025-03-13T18:14:39.433948Z"}},"outputs":[{"name":"stdout","text":"['<|begin_of_text|>', '<|end_of_text|>', '<|finetune_right_pad_id|>']\n","output_type":"stream"}],"execution_count":87},{"id":"3b21b2a1-e587-482a-84e9-233faca943eb","cell_type":"code","source":"train_dataset = OCRDataset(train_data, processor)\nsample = train_dataset[0]\nprint(sample)  # Print the first processed sample\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:14:40.445317Z","iopub.execute_input":"2025-03-13T18:14:40.445598Z","iopub.status.idle":"2025-03-13T18:14:40.481115Z","shell.execute_reply.started":"2025-03-13T18:14:40.445577Z","shell.execute_reply":"2025-03-13T18:14:40.479939Z"},"scrolled":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-88-7eaf1af111e5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOCRDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print the first processed sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-83-40e48c597c23>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"<image> {item['text']}\"\u001b[0m  \u001b[0;31m# Ensure image token is there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'image'"],"ename":"KeyError","evalue":"'image'","output_type":"error"}],"execution_count":88},{"id":"887ce621-e46a-4234-be74-4084f279476b","cell_type":"code","source":"# Create dataset & dataloader\nfrom transformers import DataCollatorForSeq2Seq\ntrain_dataset = OCRDataset(train_data, processor)\ndef collate_fn(batch):\n    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n    labels = [item[\"input_ids\"] for item in batch]  # Adjust based on your model's input format\n    return {\"pixel_values\": pixel_values, \"labels\": labels}\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n\n# train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=processor.tokenizer, \n    padding=True,  # ✅ Ensures all sequences in batch have the same length\n    # truncation=True,  # ✅ Avoids excessive length causing tensor stacking errors\n    return_tensors=\"pt\"\n)\n\n# Define training arguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./llama-finetuned\",\n    per_device_train_batch_size=2,\n    num_train_epochs=5,\n    save_steps=10,\n    logging_steps=5,\n    save_total_limit=2,\n    eval_strategy=\"no\",\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    fp16=True,\n    report_to=\"none\"\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    tokenizer=processor.tokenizer,\n    train_dataset=train_dataset\n)\n\n# Start fine-tuning\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:15:36.277047Z","iopub.execute_input":"2025-03-13T18:15:36.277349Z","iopub.status.idle":"2025-03-13T18:15:36.854377Z","shell.execute_reply.started":"2025-03-13T18:15:36.277325Z","shell.execute_reply":"2025-03-13T18:15:36.853073Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-90-3e0630a24111>:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-90-3e0630a24111>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Start fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2470\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2473\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5130\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5131\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5132\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5133\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-83-40e48c597c23>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"<image> {item['text']}\"\u001b[0m  \u001b[0;31m# Ensure image token is there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'image'"],"ename":"KeyError","evalue":"'image'","output_type":"error"}],"execution_count":90},{"id":"9c28b86a-2942-4eb8-902e-3e85bdf59171","cell_type":"code","source":"model.save_pretrained(\"./llama-finetuned\")\nprocessor.save_pretrained(\"./llama-finetuned\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}